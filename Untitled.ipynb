{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as torch_utils\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import Custom Module\n",
    "from translation.dataset import CustomDataset, PadCollate\n",
    "from translation.model import Transformer\n",
    "from translation.optimizer import Ralamb, WarmupLinearSchedule\n",
    "from translation.rnn_model import Encoder, Decoder, Seq2Seq\n",
    "from named_entity_recognition.model import NER_model\n",
    "from utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='NMT argparser')\n",
    "parser.add_argument('--save_path', default='./save2', \n",
    "                    type=str, help='path of data pickle file (train)')\n",
    "parser.add_argument('--resume', action='store_true',\n",
    "                    help='If not store, then training from scratch')\n",
    "parser.add_argument('--baseline', action='store_true',\n",
    "                    help='If not store, then training from Dynamic Word Embedding')\n",
    "parser.add_argument('--model_setting', default='transformer', choices=['transformer', 'rnn'],\n",
    "                    type=str, help='Model Selection; transformer vs rnn')\n",
    "parser.add_argument('--pad_idx', default=0, type=int, help='pad index')\n",
    "parser.add_argument('--bos_idx', default=1, type=int, help='index of bos token')\n",
    "parser.add_argument('--eos_idx', default=2, type=int, help='index of eos token')\n",
    "parser.add_argument('--unk_idx', default=3, type=int, help='index of unk token')\n",
    "\n",
    "parser.add_argument('--min_len', type=int, default=4, help='Minimum Length of Sentences; Default is 4')\n",
    "parser.add_argument('--max_len', type=int, default=300, help='Max Length of Source Sentence; Default is 150')\n",
    "\n",
    "parser.add_argument('--num_epoch', type=int, default=10, help='Epoch count; Default is 10')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='Batch size; Default is 48')\n",
    "parser.add_argument('--lr', type=float, default=5e-5, help='Learning rate; Default is 5e-5')\n",
    "parser.add_argument('--lr_decay', type=float, default=0.5, help='Learning rate decay; Default is 0.5')\n",
    "parser.add_argument('--lr_decay_step', type=int, default=2, help='Learning rate decay step; Default is 5')\n",
    "parser.add_argument('--grad_clip', type=int, default=5, help='Set gradient clipping; Default is 5')\n",
    "parser.add_argument('--w_decay', type=float, default=1e-6, help='Weight decay; Default is 1e-6')\n",
    "\n",
    "parser.add_argument('--d_model', type=int, default=512, help='Hidden State Vector Dimension; Default is 512')\n",
    "parser.add_argument('--d_embedding', type=int, default=256, help='Embedding Vector Dimension; Default is 256')\n",
    "parser.add_argument('--n_head', type=int, default=8, help='Multihead Count; Default is 256')\n",
    "parser.add_argument('--dim_feedforward', type=int, default=512, help='Embedding Vector Dimension; Default is 512')\n",
    "parser.add_argument('--num_encoder_layer', default=8, type=int, help='number of encoder layer')\n",
    "parser.add_argument('--num_decoder_layer', default=8, type=int, help='number of decoder layer')\n",
    "parser.add_argument('--dropout', type=float, default=0.3, help='Dropout Ratio; Default is 0.5')\n",
    "\n",
    "parser.add_argument('--print_freq', type=int, default=300, help='Print train loss frequency; Default is 100')\n",
    "args = parser.parse_args(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.d_model=768\n",
    "args.dim_feedforward=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Load & Setting!\n",
      "Build model\n",
      "Total Parameters: 65091008\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#===================================#\n",
    "#============Data Load==============#\n",
    "#===================================#\n",
    "\n",
    "print('Data Load & Setting!')\n",
    "with open(os.path.join(args.save_path, 'nmt_processed.pkl'), 'rb') as f:\n",
    "    data_ = pickle.load(f)\n",
    "    hj_train_indices = data_['hj_train_indices']\n",
    "    hj_test_indices = data_['hj_test_indices']\n",
    "    kr_train_indices = data_['kr_train_indices']\n",
    "    kr_test_indices = data_['kr_test_indices']\n",
    "    king_train_indices = data_['king_train_indices']\n",
    "    king_test_indices = data_['king_test_indices']\n",
    "    hj_word2id = data_['hj_word2id']\n",
    "    hj_id2word = data_['hj_id2word']\n",
    "    kr_word2id = data_['kr_word2id']\n",
    "    kr_id2word = data_['kr_id2word']\n",
    "    src_vocab_num = len(hj_word2id.keys())\n",
    "    trg_vocab_num = len(kr_word2id.keys())\n",
    "    del data_\n",
    "\n",
    "#===================================#\n",
    "#========DataLoader Setting=========#\n",
    "#===================================#\n",
    "\n",
    "dataset_dict = {\n",
    "    'train': CustomDataset(hj_train_indices, kr_train_indices, king_train_indices,\n",
    "                        min_len=args.min_len, max_len=args.max_len),\n",
    "    'valid': CustomDataset(hj_test_indices, kr_test_indices, king_test_indices,\n",
    "                        min_len=args.min_len, max_len=args.max_len)\n",
    "}\n",
    "dataloader_dict = {\n",
    "    'train': DataLoader(dataset_dict['train'], collate_fn=PadCollate(), drop_last=True,\n",
    "                        batch_size=args.batch_size, shuffle=True, pin_memory=True),\n",
    "    'valid': DataLoader(dataset_dict['valid'], collate_fn=PadCollate(), drop_last=True,\n",
    "                        batch_size=args.batch_size, shuffle=True, pin_memory=True)\n",
    "}\n",
    "\n",
    "#====================================#\n",
    "#==========DWE Results Open==========#\n",
    "#====================================#\n",
    "\n",
    "with open(os.path.join(args.save_path, 'emb_mat.pkl'), 'rb') as f:\n",
    "    emb_mat = pickle.load(f)\n",
    "\n",
    "#===================================#\n",
    "#===========Model Setting===========#\n",
    "#===================================#\n",
    "\n",
    "print(\"Build model\")\n",
    "if args.model_setting == 'transformer':\n",
    "    model = Transformer(emb_mat, hj_word2id, src_vocab_num, trg_vocab_num, pad_idx=args.pad_idx, bos_idx=args.bos_idx, \n",
    "                eos_idx=args.eos_idx, max_len=args.max_len,\n",
    "                d_model=args.d_model, d_embedding=args.d_embedding, n_head=args.n_head, \n",
    "                dim_feedforward=args.dim_feedforward, dropout=args.dropout,\n",
    "                num_encoder_layer=args.num_encoder_layer, num_decoder_layer=args.num_decoder_layer,\n",
    "                baseline=args.baseline, device=device)\n",
    "elif args.model_setting == 'rnn':\n",
    "    encoder = Encoder(src_vocab_num, args.d_embedding, args.d_model, \n",
    "                    emb_mat, hj_word2id, n_layers=args.num_encoder_layer, \n",
    "                    pad_idx=args.pad_idx, dropout=args.dropout)\n",
    "    decoder = Decoder(args.d_embedding, args.d_model, trg_vocab_num, n_layers=args.num_decoder_layer, \n",
    "                    pad_idx=args.pad_idx, dropout=args.dropout)\n",
    "    model = Seq2Seq(encoder, decoder, device)\n",
    "else:\n",
    "    raise Exception('Model error')\n",
    "\n",
    "if args.resume:\n",
    "    model_ner = NER_model(emb_mat=emb_mat, word2id=hj_word2id, pad_idx=args.pad_idx, bos_idx=args.bos_idx, eos_idx=args.eos_idx, max_len=args.max_len,\n",
    "                    d_model=args.d_model, d_embedding=args.d_embedding, n_head=args.n_head,\n",
    "                    dim_feedforward=args.dim_feedforward, n_layers=args.num_encoder_layer, dropout=args.dropout,\n",
    "                    crf_loss=args.crf_loss, device=device)\n",
    "    model_ner.load_state_dict(torch.load(os.path.join(args.save_path, 'ner_model_False.pt')))\n",
    "    model.transformer_encoder.load_state_dict(model_ner.transformer_encoder.state_dict())\n",
    "    for param in model.transformer_encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "print(\"Total Parameters:\", sum([p.nelement() for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./save2/nmt_model_False.pt'))\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63390 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "total_trg_list = list()\n",
    "total_pred_list = list()\n",
    "\n",
    "for src, trg, king_id in tqdm(dataloader_dict['valid']):\n",
    "    # Sourcen, Target sentence setting\n",
    "    label_sequences = trg.to(device, non_blocking=True)\n",
    "    input_sequences = src.to(device, non_blocking=True)\n",
    "    king_id = king_id.to(device, non_blocking=True)\n",
    "\n",
    "    non_pad = label_sequences != args.pad_idx\n",
    "    trg_sequences_target = label_sequences[non_pad].contiguous().view(-1)\n",
    "\n",
    "    if args.model_setting == 'transformer':\n",
    "        # Target Masking\n",
    "        tgt_mask = model.generate_square_subsequent_mask(label_sequences.size(1))\n",
    "        tgt_mask = tgt_mask.to(device, non_blocking=True)\n",
    "        tgt_mask = tgt_mask.transpose(0, 1)\n",
    "    break\n",
    "\n",
    "    # Model / Calculate loss\n",
    "    with torch.no_grad():\n",
    "        if args.model_setting == 'transformer':\n",
    "            predicted = model(input_sequences, label_sequences, king_id, tgt_mask, non_pad)\n",
    "    start = 0\n",
    "    trg_list = list()\n",
    "    pred_list = list()\n",
    "    for end_ix in torch.where(trg_sequences_target==2)[0]:\n",
    "        trg_list.append(trg_sequences_target[start:end_ix+1].tolist())\n",
    "        _, pred = predicted.topk(1, 1, True, True)\n",
    "        pred_list.append(pred.squeeze(1)[start:end_ix+1].tolist())\n",
    "        start=end_ix+1\n",
    "    total_trg_list.extend(trg_list)\n",
    "    total_pred_list.extend(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,   13,  530,  112,   20,   13,  530,  149, 6633,   23,   24, 3203,\n",
       "          296,   56,    3,    6,  273,   68,  129, 4459,  123,  517,  890,  150,\n",
       "          306,  360,   41,    3,    6, 4459, 1443,  123,  929,  243,  150,  306,\n",
       "          360,   41,    3,    6,   68, 3081, 3252, 2496,  567,  119, 3919,    3,\n",
       "            6,   15, 1555,   89,  727,    3,    6,  267,  534,  188,  169,  148,\n",
       "           37,    3,    6,  151,   56,    3,    6,    3,   87,  448,  214,   34,\n",
       "           64,    3,    6,  125,   12,   51, 1061,   34,  385,  895,  154, 1860,\n",
       "          420,  658,    3,    3,    2]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = model.src_embedding(input_sequences, king_id).transpose(0, 1)\n",
    "src_key_padding_mask = (input_sequences == model.pad_idx)\n",
    "predicted = torch.LongTensor([[model.bos_idx]]).repeat(encoder_out.size(1), 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = model.transformer_encoder(encoder_out, src_key_padding_mask=src_key_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/300 [00:00<00:09, 30.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/300 [00:00<00:09, 29.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/300 [00:00<00:10, 27.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 30/300 [00:00<00:07, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/300 [00:01<00:05, 48.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 58/300 [00:01<00:04, 57.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 65/300 [00:01<00:04, 56.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 71/300 [00:01<00:06, 37.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "69\n",
      "70\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 76/300 [00:01<00:08, 27.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "73\n",
      "74\n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 80/300 [00:02<00:09, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "77\n",
      "78\n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 84/300 [00:02<00:10, 20.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "81\n",
      "82\n",
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/300 [00:02<00:08, 25.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 96/300 [00:02<00:07, 27.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 104/300 [00:03<00:06, 28.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 112/300 [00:03<00:06, 31.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 120/300 [00:03<00:05, 33.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 134/300 [00:03<00:03, 44.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 148/300 [00:03<00:02, 53.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 161/300 [00:04<00:02, 56.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 175/300 [00:04<00:02, 60.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 182/300 [00:04<00:03, 33.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "180\n",
      "181\n",
      "182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 187/300 [00:05<00:04, 25.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "184\n",
      "185\n",
      "186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 191/300 [00:05<00:05, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "188\n",
      "189\n",
      "190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 195/300 [00:05<00:04, 22.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 199/300 [00:06<00:07, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 209/300 [00:06<00:05, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 222/300 [00:06<00:03, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 236/300 [00:06<00:01, 36.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 244/300 [00:07<00:01, 43.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 251/300 [00:07<00:01, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 256/300 [00:07<00:01, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "256\n",
      "257\n",
      "258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 264/300 [00:08<00:01, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 268/300 [00:08<00:02, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 275/300 [00:08<00:01, 16.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 285/300 [00:09<00:01, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:09<00:00, 30.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(model.max_len)):\n",
    "    tgt_mask = model.generate_square_subsequent_mask(predicted.size(1))\n",
    "    tgt_mask = tgt_mask.to(device, non_blocking=True).transpose(0, 1)\n",
    "\n",
    "    tgt_key_padding_mask = (predicted == model.pad_idx)\n",
    "    decoder_out = model.trg_embedding(predicted).transpose(0, 1)\n",
    "\n",
    "    for i in range(len(model.decoders)):            \n",
    "        decoder_out = model.decoders[i](decoder_out, encoder_out, tgt_mask=tgt_mask, \n",
    "                                        memory_key_padding_mask=src_key_padding_mask,\n",
    "                                        tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "    decoder_out = F.gelu(model.trg_output_linear(decoder_out[-1]))\n",
    "    y_pred = model.trg_output_linear2(decoder_out)\n",
    "    y_pred_id = y_pred.max(dim=1)[1].unsqueeze(1)\n",
    "\n",
    "    predicted = torch.cat([predicted, y_pred_id], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
