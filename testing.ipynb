{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as torch_utils\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import Custom Module\n",
    "from translation.dataset import HanjaKoreanDataset, PadCollate, CustomDataset\n",
    "from translation.model import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='NER argparser')\n",
    "parser.add_argument('--save_path', default='./save', \n",
    "                    type=str, help='path of data pickle file (train)')\n",
    "parser.add_argument('--pad_idx', default=0, type=int, help='pad index')\n",
    "parser.add_argument('--bos_idx', default=1, type=int, help='index of bos token')\n",
    "parser.add_argument('--eos_idx', default=2, type=int, help='index of eos token')\n",
    "parser.add_argument('--unk_idx', default=3, type=int, help='index of unk token')\n",
    "\n",
    "parser.add_argument('--min_len', type=int, default=4, help='Minimum Length of Sentences; Default is 4')\n",
    "parser.add_argument('--max_len', type=int, default=150, help='Max Length of Source Sentence; Default is 150')\n",
    "parser.add_argument('--src_max_len', default=350, type=int, help='max length of the source sentence')\n",
    "parser.add_argument('--trg_max_len', default=300, type=int, help='max length of the target sentence')\n",
    "\n",
    "parser.add_argument('--num_epoch', type=int, default=10, help='Epoch count; Default is 10')\n",
    "parser.add_argument('--batch_size', type=int, default=48, help='Batch size; Default is 48')\n",
    "parser.add_argument('--crf_loss', action='store_true')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate; Default is 5e-4')\n",
    "parser.add_argument('--lr_decay', type=float, default=0.5, help='Learning rate decay; Default is 0.5')\n",
    "parser.add_argument('--lr_decay_step', type=int, default=2, help='Learning rate decay step; Default is 5')\n",
    "parser.add_argument('--grad_clip', type=int, default=5, help='Set gradient clipping; Default is 5')\n",
    "parser.add_argument('--w_decay', type=float, default=1e-6, help='Weight decay; Default is 1e-6')\n",
    "\n",
    "parser.add_argument('--d_model', type=int, default=512, help='Hidden State Vector Dimension; Default is 512')\n",
    "parser.add_argument('--d_embedding', type=int, default=256, help='Embedding Vector Dimension; Default is 256')\n",
    "parser.add_argument('--n_head', type=int, default=8, help='Multihead Count; Default is 256')\n",
    "parser.add_argument('--dim_feedforward', type=int, default=512, help='Embedding Vector Dimension; Default is 512')\n",
    "parser.add_argument('--num_encoder_layer', default=8, type=int, help='number of encoder layer')\n",
    "parser.add_argument('--num_decoder_layer', default=8, type=int, help='number of decoder layer')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='Dropout Ratio; Default is 0.5')\n",
    "\n",
    "parser.add_argument('--print_freq', type=int, default=300, help='Print train loss frequency; Default is 100')\n",
    "args = parser.parse_args(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Load & Setting!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#===================================#\n",
    "#============Data Load==============#\n",
    "#===================================#\n",
    "\n",
    "print('Data Load & Setting!')\n",
    "with open(os.path.join(args.save_path, 'nmt_processed.pkl'), 'rb') as f:\n",
    "    data_ = pickle.load(f)\n",
    "    hj_train_indices = data_['hj_train_indices']\n",
    "    hj_test_indices = data_['hj_test_indices']\n",
    "    kr_train_indices = data_['kr_train_indices']\n",
    "    kr_test_indices = data_['kr_test_indices']\n",
    "    king_train_indices = data_['king_train_indices']\n",
    "    king_test_indices = data_['king_test_indices']\n",
    "    hj_word2id = data_['hj_word2id']\n",
    "    hj_id2word = data_['hj_id2word']\n",
    "    kr_word2id = data_['kr_word2id']\n",
    "    kr_id2word = data_['kr_id2word']\n",
    "    src_vocab_num = len(hj_word2id.keys())\n",
    "    trg_vocab_num = len(kr_word2id.keys())\n",
    "    del data_\n",
    "\n",
    "#===================================#\n",
    "#========DataLoader Setting=========#\n",
    "#===================================#\n",
    "\n",
    "dataset_dict = {\n",
    "    'train': CustomDataset(hj_train_indices, kr_train_indices, king_train_indices,\n",
    "                        min_len=args.min_len, max_len=args.max_len),\n",
    "    'valid': CustomDataset(hj_test_indices, kr_test_indices, king_test_indices,\n",
    "                        min_len=args.min_len, max_len=args.max_len)\n",
    "}\n",
    "dataloader_dict = {\n",
    "    'train': DataLoader(dataset_dict['train'], collate_fn=PadCollate(), drop_last=True,\n",
    "                        batch_size=args.batch_size, shuffle=True, pin_memory=True),\n",
    "    'valid': DataLoader(dataset_dict['valid'], collate_fn=PadCollate(), drop_last=True,\n",
    "                        batch_size=args.batch_size, shuffle=True, pin_memory=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model\n",
      "Total Parameters: 69195008\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#====================================#\n",
    "#==========DWE Results Open==========#\n",
    "#====================================#\n",
    "\n",
    "with open(os.path.join(args.save_path, 'emb_mat.pkl'), 'rb') as f:\n",
    "    emb_mat = pickle.load(f)\n",
    "\n",
    "#===================================#\n",
    "#===========Model Setting===========#\n",
    "#===================================#\n",
    "\n",
    "print(\"Build model\")\n",
    "model = Transformer(emb_mat, kr_word2id, src_vocab_num, trg_vocab_num, pad_idx=args.pad_idx, bos_idx=args.bos_idx, \n",
    "            eos_idx=args.eos_idx, max_len=args.max_len,\n",
    "            d_model=args.d_model, d_embedding=args.d_embedding, n_head=args.n_head, \n",
    "            dim_feedforward=args.dim_feedforward, dropout=args.dropout,\n",
    "            num_encoder_layer=args.num_encoder_layer, num_decoder_layer=args.num_decoder_layer,\n",
    "            device=device)\n",
    "print(\"Total Parameters:\", sum([p.nelement() for p in model.parameters()]))\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, weight_decay=args.w_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_decay_step, gamma=args.lr_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from named_entity_recognition.model import NER_model\n",
    "model_ner = NER_model(emb_mat=emb_mat, word2id=hj_word2id, pad_idx=args.pad_idx, bos_idx=args.bos_idx, eos_idx=args.eos_idx, max_len=args.max_len,\n",
    "                d_model=args.d_model, d_embedding=args.d_embedding, n_head=args.n_head,\n",
    "                dim_feedforward=args.dim_feedforward, n_layers=args.num_encoder_layer, dropout=args.dropout,\n",
    "                crf_loss=args.crf_loss, device=device)\n",
    "model_ner.load_state_dict(torch.load('./save/ner_model_False.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer_encoder.load_state_dict(model_ner.transformer_encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.0.linear1.weight\n",
      "transformer_encoder.layers.0.linear1.bias\n",
      "transformer_encoder.layers.0.linear2.weight\n",
      "transformer_encoder.layers.0.linear2.bias\n",
      "transformer_encoder.layers.0.norm1.weight\n",
      "transformer_encoder.layers.0.norm1.bias\n",
      "transformer_encoder.layers.0.norm2.weight\n",
      "transformer_encoder.layers.0.norm2.bias\n",
      "transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.1.linear1.weight\n",
      "transformer_encoder.layers.1.linear1.bias\n",
      "transformer_encoder.layers.1.linear2.weight\n",
      "transformer_encoder.layers.1.linear2.bias\n",
      "transformer_encoder.layers.1.norm1.weight\n",
      "transformer_encoder.layers.1.norm1.bias\n",
      "transformer_encoder.layers.1.norm2.weight\n",
      "transformer_encoder.layers.1.norm2.bias\n",
      "transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.2.linear1.weight\n",
      "transformer_encoder.layers.2.linear1.bias\n",
      "transformer_encoder.layers.2.linear2.weight\n",
      "transformer_encoder.layers.2.linear2.bias\n",
      "transformer_encoder.layers.2.norm1.weight\n",
      "transformer_encoder.layers.2.norm1.bias\n",
      "transformer_encoder.layers.2.norm2.weight\n",
      "transformer_encoder.layers.2.norm2.bias\n",
      "transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.3.linear1.weight\n",
      "transformer_encoder.layers.3.linear1.bias\n",
      "transformer_encoder.layers.3.linear2.weight\n",
      "transformer_encoder.layers.3.linear2.bias\n",
      "transformer_encoder.layers.3.norm1.weight\n",
      "transformer_encoder.layers.3.norm1.bias\n",
      "transformer_encoder.layers.3.norm2.weight\n",
      "transformer_encoder.layers.3.norm2.bias\n",
      "transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.4.linear1.weight\n",
      "transformer_encoder.layers.4.linear1.bias\n",
      "transformer_encoder.layers.4.linear2.weight\n",
      "transformer_encoder.layers.4.linear2.bias\n",
      "transformer_encoder.layers.4.norm1.weight\n",
      "transformer_encoder.layers.4.norm1.bias\n",
      "transformer_encoder.layers.4.norm2.weight\n",
      "transformer_encoder.layers.4.norm2.bias\n",
      "transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.5.linear1.weight\n",
      "transformer_encoder.layers.5.linear1.bias\n",
      "transformer_encoder.layers.5.linear2.weight\n",
      "transformer_encoder.layers.5.linear2.bias\n",
      "transformer_encoder.layers.5.norm1.weight\n",
      "transformer_encoder.layers.5.norm1.bias\n",
      "transformer_encoder.layers.5.norm2.weight\n",
      "transformer_encoder.layers.5.norm2.bias\n",
      "transformer_encoder.layers.6.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.6.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.6.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.6.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.6.linear1.weight\n",
      "transformer_encoder.layers.6.linear1.bias\n",
      "transformer_encoder.layers.6.linear2.weight\n",
      "transformer_encoder.layers.6.linear2.bias\n",
      "transformer_encoder.layers.6.norm1.weight\n",
      "transformer_encoder.layers.6.norm1.bias\n",
      "transformer_encoder.layers.6.norm2.weight\n",
      "transformer_encoder.layers.6.norm2.bias\n",
      "transformer_encoder.layers.7.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.7.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.7.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.7.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.7.linear1.weight\n",
      "transformer_encoder.layers.7.linear1.bias\n",
      "transformer_encoder.layers.7.linear2.weight\n",
      "transformer_encoder.layers.7.linear2.bias\n",
      "transformer_encoder.layers.7.norm1.weight\n",
      "transformer_encoder.layers.7.norm1.bias\n",
      "transformer_encoder.layers.7.norm2.weight\n",
      "transformer_encoder.layers.7.norm2.bias\n"
     ]
    }
   ],
   "source": [
    "for l in list(resume_.keys())[5:-4]:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransformerEncoder:\n\tMissing key(s) in state_dict: \"layers.0.self_attn.in_proj_weight\", \"layers.0.self_attn.in_proj_bias\", \"layers.0.self_attn.out_proj.weight\", \"layers.0.self_attn.out_proj.bias\", \"layers.0.linear1.weight\", \"layers.0.linear1.bias\", \"layers.0.linear2.weight\", \"layers.0.linear2.bias\", \"layers.0.norm1.weight\", \"layers.0.norm1.bias\", \"layers.0.norm2.weight\", \"layers.0.norm2.bias\", \"layers.1.self_attn.in_proj_weight\", \"layers.1.self_attn.in_proj_bias\", \"layers.1.self_attn.out_proj.weight\", \"layers.1.self_attn.out_proj.bias\", \"layers.1.linear1.weight\", \"layers.1.linear1.bias\", \"layers.1.linear2.weight\", \"layers.1.linear2.bias\", \"layers.1.norm1.weight\", \"layers.1.norm1.bias\", \"layers.1.norm2.weight\", \"layers.1.norm2.bias\", \"layers.2.self_attn.in_proj_weight\", \"layers.2.self_attn.in_proj_bias\", \"layers.2.self_attn.out_proj.weight\", \"layers.2.self_attn.out_proj.bias\", \"layers.2.linear1.weight\", \"layers.2.linear1.bias\", \"layers.2.linear2.weight\", \"layers.2.linear2.bias\", \"layers.2.norm1.weight\", \"layers.2.norm1.bias\", \"layers.2.norm2.weight\", \"layers.2.norm2.bias\", \"layers.3.self_attn.in_proj_weight\", \"layers.3.self_attn.in_proj_bias\", \"layers.3.self_attn.out_proj.weight\", \"layers.3.self_attn.out_proj.bias\", \"layers.3.linear1.weight\", \"layers.3.linear1.bias\", \"layers.3.linear2.weight\", \"layers.3.linear2.bias\", \"layers.3.norm1.weight\", \"layers.3.norm1.bias\", \"layers.3.norm2.weight\", \"layers.3.norm2.bias\", \"layers.4.self_attn.in_proj_weight\", \"layers.4.self_attn.in_proj_bias\", \"layers.4.self_attn.out_proj.weight\", \"layers.4.self_attn.out_proj.bias\", \"layers.4.linear1.weight\", \"layers.4.linear1.bias\", \"layers.4.linear2.weight\", \"layers.4.linear2.bias\", \"layers.4.norm1.weight\", \"layers.4.norm1.bias\", \"layers.4.norm2.weight\", \"layers.4.norm2.bias\", \"layers.5.self_attn.in_proj_weight\", \"layers.5.self_attn.in_proj_bias\", \"layers.5.self_attn.out_proj.weight\", \"layers.5.self_attn.out_proj.bias\", \"layers.5.linear1.weight\", \"layers.5.linear1.bias\", \"layers.5.linear2.weight\", \"layers.5.linear2.bias\", \"layers.5.norm1.weight\", \"layers.5.norm1.bias\", \"layers.5.norm2.weight\", \"layers.5.norm2.bias\", \"layers.6.self_attn.in_proj_weight\", \"layers.6.self_attn.in_proj_bias\", \"layers.6.self_attn.out_proj.weight\", \"layers.6.self_attn.out_proj.bias\", \"layers.6.linear1.weight\", \"layers.6.linear1.bias\", \"layers.6.linear2.weight\", \"layers.6.linear2.bias\", \"layers.6.norm1.weight\", \"layers.6.norm1.bias\", \"layers.6.norm2.weight\", \"layers.6.norm2.bias\", \"layers.7.self_attn.in_proj_weight\", \"layers.7.self_attn.in_proj_bias\", \"layers.7.self_attn.out_proj.weight\", \"layers.7.self_attn.out_proj.bias\", \"layers.7.linear1.weight\", \"layers.7.linear1.bias\", \"layers.7.linear2.weight\", \"layers.7.linear2.bias\", \"layers.7.norm1.weight\", \"layers.7.norm1.bias\", \"layers.7.norm2.weight\", \"layers.7.norm2.bias\". \n\tUnexpected key(s) in state_dict: \"src_embedding.norm.weight\", \"src_embedding.norm.bias\", \"src_embedding.linear_layer.weight\", \"src_embedding.linear_layer.bias\", \"src_embedding.king_embedding.weight\", \"transformer_encoder.layers.0.self_attn.in_proj_weight\", \"transformer_encoder.layers.0.self_attn.in_proj_bias\", \"transformer_encoder.layers.0.self_attn.out_proj.weight\", \"transformer_encoder.layers.0.self_attn.out_proj.bias\", \"transformer_encoder.layers.0.linear1.weight\", \"transformer_encoder.layers.0.linear1.bias\", \"transformer_encoder.layers.0.linear2.weight\", \"transformer_encoder.layers.0.linear2.bias\", \"transformer_encoder.layers.0.norm1.weight\", \"transformer_encoder.layers.0.norm1.bias\", \"transformer_encoder.layers.0.norm2.weight\", \"transformer_encoder.layers.0.norm2.bias\", \"transformer_encoder.layers.1.self_attn.in_proj_weight\", \"transformer_encoder.layers.1.self_attn.in_proj_bias\", \"transformer_encoder.layers.1.self_attn.out_proj.weight\", \"transformer_encoder.layers.1.self_attn.out_proj.bias\", \"transformer_encoder.layers.1.linear1.weight\", \"transformer_encoder.layers.1.linear1.bias\", \"transformer_encoder.layers.1.linear2.weight\", \"transformer_encoder.layers.1.linear2.bias\", \"transformer_encoder.layers.1.norm1.weight\", \"transformer_encoder.layers.1.norm1.bias\", \"transformer_encoder.layers.1.norm2.weight\", \"transformer_encoder.layers.1.norm2.bias\", \"transformer_encoder.layers.2.self_attn.in_proj_weight\", \"transformer_encoder.layers.2.self_attn.in_proj_bias\", \"transformer_encoder.layers.2.self_attn.out_proj.weight\", \"transformer_encoder.layers.2.self_attn.out_proj.bias\", \"transformer_encoder.layers.2.linear1.weight\", \"transformer_encoder.layers.2.linear1.bias\", \"transformer_encoder.layers.2.linear2.weight\", \"transformer_encoder.layers.2.linear2.bias\", \"transformer_encoder.layers.2.norm1.weight\", \"transformer_encoder.layers.2.norm1.bias\", \"transformer_encoder.layers.2.norm2.weight\", \"transformer_encoder.layers.2.norm2.bias\", \"transformer_encoder.layers.3.self_attn.in_proj_weight\", \"transformer_encoder.layers.3.self_attn.in_proj_bias\", \"transformer_encoder.layers.3.self_attn.out_proj.weight\", \"transformer_encoder.layers.3.self_attn.out_proj.bias\", \"transformer_encoder.layers.3.linear1.weight\", \"transformer_encoder.layers.3.linear1.bias\", \"transformer_encoder.layers.3.linear2.weight\", \"transformer_encoder.layers.3.linear2.bias\", \"transformer_encoder.layers.3.norm1.weight\", \"transformer_encoder.layers.3.norm1.bias\", \"transformer_encoder.layers.3.norm2.weight\", \"transformer_encoder.layers.3.norm2.bias\", \"transformer_encoder.layers.4.self_attn.in_proj_weight\", \"transformer_encoder.layers.4.self_attn.in_proj_bias\", \"transformer_encoder.layers.4.self_attn.out_proj.weight\", \"transformer_encoder.layers.4.self_attn.out_proj.bias\", \"transformer_encoder.layers.4.linear1.weight\", \"transformer_encoder.layers.4.linear1.bias\", \"transformer_encoder.layers.4.linear2.weight\", \"transformer_encoder.layers.4.linear2.bias\", \"transformer_encoder.layers.4.norm1.weight\", \"transformer_encoder.layers.4.norm1.bias\", \"transformer_encoder.layers.4.norm2.weight\", \"transformer_encoder.layers.4.norm2.bias\", \"transformer_encoder.layers.5.self_attn.in_proj_weight\", \"transformer_encoder.layers.5.self_attn.in_proj_bias\", \"transformer_encoder.layers.5.self_attn.out_proj.weight\", \"transformer_encoder.layers.5.self_attn.out_proj.bias\", \"transformer_encoder.layers.5.linear1.weight\", \"transformer_encoder.layers.5.linear1.bias\", \"transformer_encoder.layers.5.linear2.weight\", \"transformer_encoder.layers.5.linear2.bias\", \"transformer_encoder.layers.5.norm1.weight\", \"transformer_encoder.layers.5.norm1.bias\", \"transformer_encoder.layers.5.norm2.weight\", \"transformer_encoder.layers.5.norm2.bias\", \"transformer_encoder.layers.6.self_attn.in_proj_weight\", \"transformer_encoder.layers.6.self_attn.in_proj_bias\", \"transformer_encoder.layers.6.self_attn.out_proj.weight\", \"transformer_encoder.layers.6.self_attn.out_proj.bias\", \"transformer_encoder.layers.6.linear1.weight\", \"transformer_encoder.layers.6.linear1.bias\", \"transformer_encoder.layers.6.linear2.weight\", \"transformer_encoder.layers.6.linear2.bias\", \"transformer_encoder.layers.6.norm1.weight\", \"transformer_encoder.layers.6.norm1.bias\", \"transformer_encoder.layers.6.norm2.weight\", \"transformer_encoder.layers.6.norm2.bias\", \"transformer_encoder.layers.7.self_attn.in_proj_weight\", \"transformer_encoder.layers.7.self_attn.in_proj_bias\", \"transformer_encoder.layers.7.self_attn.out_proj.weight\", \"transformer_encoder.layers.7.self_attn.out_proj.bias\", \"transformer_encoder.layers.7.linear1.weight\", \"transformer_encoder.layers.7.linear1.bias\", \"transformer_encoder.layers.7.linear2.weight\", \"transformer_encoder.layers.7.linear2.bias\", \"transformer_encoder.layers.7.norm1.weight\", \"transformer_encoder.layers.7.norm1.bias\", \"transformer_encoder.layers.7.norm2.weight\", \"transformer_encoder.layers.7.norm2.bias\", \"src_output_linear.weight\", \"src_output_linear.bias\", \"src_output_linear2.weight\", \"src_output_linear2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d10575c561c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 847\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TransformerEncoder:\n\tMissing key(s) in state_dict: \"layers.0.self_attn.in_proj_weight\", \"layers.0.self_attn.in_proj_bias\", \"layers.0.self_attn.out_proj.weight\", \"layers.0.self_attn.out_proj.bias\", \"layers.0.linear1.weight\", \"layers.0.linear1.bias\", \"layers.0.linear2.weight\", \"layers.0.linear2.bias\", \"layers.0.norm1.weight\", \"layers.0.norm1.bias\", \"layers.0.norm2.weight\", \"layers.0.norm2.bias\", \"layers.1.self_attn.in_proj_weight\", \"layers.1.self_attn.in_proj_bias\", \"layers.1.self_attn.out_proj.weight\", \"layers.1.self_attn.out_proj.bias\", \"layers.1.linear1.weight\", \"layers.1.linear1.bias\", \"layers.1.linear2.weight\", \"layers.1.linear2.bias\", \"layers.1.norm1.weight\", \"layers.1.norm1.bias\", \"layers.1.norm2.weight\", \"layers.1.norm2.bias\", \"layers.2.self_attn.in_proj_weight\", \"layers.2.self_attn.in_proj_bias\", \"layers.2.self_attn.out_proj.weight\", \"layers.2.self_attn.out_proj.bias\", \"layers.2.linear1.weight\", \"layers.2.linear1.bias\", \"layers.2.linear2.weight\", \"layers.2.linear2.bias\", \"layers.2.norm1.weight\", \"layers.2.norm1.bias\", \"layers.2.norm2.weight\", \"layers.2.norm2.bias\", \"layers.3.self_attn.in_proj_weight\", \"layers.3.self_attn.in_proj_bias\", \"layers.3.self_attn.out_proj.weight\", \"layers.3.self_attn.out_proj.bias\", \"layers.3.linear1.weight\", \"layers.3.linear1.bias\", \"layers.3.linear2.weight\", \"layers.3.linear2.bias\", \"layers.3.norm1.weight\", \"layers.3.norm1.bias\", \"layers.3.norm2.weight\", \"layers.3.norm2.bias\", \"layers.4.self_attn.in_proj_weight\", \"layers.4.self_attn.in_proj_bias\", \"layers.4.self_attn.out_proj.weight\", \"layers.4.self_attn.out_proj.bias\", \"layers.4.linear1.weight\", \"layers.4.linear1.bias\", \"layers.4.linear2.weight\", \"layers.4.linear2.bias\", \"layers.4.norm1.weight\", \"layers.4.norm1.bias\", \"layers.4.norm2.weight\", \"layers.4.norm2.bias\", \"layers.5.self_attn.in_proj_weight\", \"layers.5.self_attn.in_proj_bias\", \"layers.5.self_attn.out_proj.weight\", \"layers.5.self_attn.out_proj.bias\", \"layers.5.linear1.weight\", \"layers.5.linear1.bias\", \"layers.5.linear2.weight\", \"layers.5.linear2.bias\", \"layers.5.norm1.weight\", \"layers.5.norm1.bias\", \"layers.5.norm2.weight\", \"layers.5.norm2.bias\", \"layers.6.self_attn.in_proj_weight\", \"layers.6.self_attn.in_proj_bias\", \"layers.6.self_attn.out_proj.weight\", \"layers.6.self_attn.out_proj.bias\", \"layers.6.linear1.weight\", \"layers.6.linear1.bias\", \"layers.6.linear2.weight\", \"layers.6.linear2.bias\", \"layers.6.norm1.weight\", \"layers.6.norm1.bias\", \"layers.6.norm2.weight\", \"layers.6.norm2.bias\", \"layers.7.self_attn.in_proj_weight\", \"layers.7.self_attn.in_proj_bias\", \"layers.7.self_attn.out_proj.weight\", \"layers.7.self_attn.out_proj.bias\", \"layers.7.linear1.weight\", \"layers.7.linear1.bias\", \"layers.7.linear2.weight\", \"layers.7.linear2.bias\", \"layers.7.norm1.weight\", \"layers.7.norm1.bias\", \"layers.7.norm2.weight\", \"layers.7.norm2.bias\". \n\tUnexpected key(s) in state_dict: \"src_embedding.norm.weight\", \"src_embedding.norm.bias\", \"src_embedding.linear_layer.weight\", \"src_embedding.linear_layer.bias\", \"src_embedding.king_embedding.weight\", \"transformer_encoder.layers.0.self_attn.in_proj_weight\", \"transformer_encoder.layers.0.self_attn.in_proj_bias\", \"transformer_encoder.layers.0.self_attn.out_proj.weight\", \"transformer_encoder.layers.0.self_attn.out_proj.bias\", \"transformer_encoder.layers.0.linear1.weight\", \"transformer_encoder.layers.0.linear1.bias\", \"transformer_encoder.layers.0.linear2.weight\", \"transformer_encoder.layers.0.linear2.bias\", \"transformer_encoder.layers.0.norm1.weight\", \"transformer_encoder.layers.0.norm1.bias\", \"transformer_encoder.layers.0.norm2.weight\", \"transformer_encoder.layers.0.norm2.bias\", \"transformer_encoder.layers.1.self_attn.in_proj_weight\", \"transformer_encoder.layers.1.self_attn.in_proj_bias\", \"transformer_encoder.layers.1.self_attn.out_proj.weight\", \"transformer_encoder.layers.1.self_attn.out_proj.bias\", \"transformer_encoder.layers.1.linear1.weight\", \"transformer_encoder.layers.1.linear1.bias\", \"transformer_encoder.layers.1.linear2.weight\", \"transformer_encoder.layers.1.linear2.bias\", \"transformer_encoder.layers.1.norm1.weight\", \"transformer_encoder.layers.1.norm1.bias\", \"transformer_encoder.layers.1.norm2.weight\", \"transformer_encoder.layers.1.norm2.bias\", \"transformer_encoder.layers.2.self_attn.in_proj_weight\", \"transformer_encoder.layers.2.self_attn.in_proj_bias\", \"transformer_encoder.layers.2.self_attn.out_proj.weight\", \"transformer_encoder.layers.2.self_attn.out_proj.bias\", \"transformer_encoder.layers.2.linear1.weight\", \"transformer_encoder.layers.2.linear1.bias\", \"transformer_encoder.layers.2.linear2.weight\", \"transformer_encoder.layers.2.linear2.bias\", \"transformer_encoder.layers.2.norm1.weight\", \"transformer_encoder.layers.2.norm1.bias\", \"transformer_encoder.layers.2.norm2.weight\", \"transformer_encoder.layers.2.norm2.bias\", \"transformer_encoder.layers.3.self_attn.in_proj_weight\", \"transformer_encoder.layers.3.self_attn.in_proj_bias\", \"transformer_encoder.layers.3.self_attn.out_proj.weight\", \"transformer_encoder.layers.3.self_attn.out_proj.bias\", \"transformer_encoder.layers.3.linear1.weight\", \"transformer_encoder.layers.3.linear1.bias\", \"transformer_encoder.layers.3.linear2.weight\", \"transformer_encoder.layers.3.linear2.bias\", \"transformer_encoder.layers.3.norm1.weight\", \"transformer_encoder.layers.3.norm1.bias\", \"transformer_encoder.layers.3.norm2.weight\", \"transformer_encoder.layers.3.norm2.bias\", \"transformer_encoder.layers.4.self_attn.in_proj_weight\", \"transformer_encoder.layers.4.self_attn.in_proj_bias\", \"transformer_encoder.layers.4.self_attn.out_proj.weight\", \"transformer_encoder.layers.4.self_attn.out_proj.bias\", \"transformer_encoder.layers.4.linear1.weight\", \"transformer_encoder.layers.4.linear1.bias\", \"transformer_encoder.layers.4.linear2.weight\", \"transformer_encoder.layers.4.linear2.bias\", \"transformer_encoder.layers.4.norm1.weight\", \"transformer_encoder.layers.4.norm1.bias\", \"transformer_encoder.layers.4.norm2.weight\", \"transformer_encoder.layers.4.norm2.bias\", \"transformer_encoder.layers.5.self_attn.in_proj_weight\", \"transformer_encoder.layers.5.self_attn.in_proj_bias\", \"transformer_encoder.layers.5.self_attn.out_proj.weight\", \"transformer_encoder.layers.5.self_attn.out_proj.bias\", \"transformer_encoder.layers.5.linear1.weight\", \"transformer_encoder.layers.5.linear1.bias\", \"transformer_encoder.layers.5.linear2.weight\", \"transformer_encoder.layers.5.linear2.bias\", \"transformer_encoder.layers.5.norm1.weight\", \"transformer_encoder.layers.5.norm1.bias\", \"transformer_encoder.layers.5.norm2.weight\", \"transformer_encoder.layers.5.norm2.bias\", \"transformer_encoder.layers.6.self_attn.in_proj_weight\", \"transformer_encoder.layers.6.self_attn.in_proj_bias\", \"transformer_encoder.layers.6.self_attn.out_proj.weight\", \"transformer_encoder.layers.6.self_attn.out_proj.bias\", \"transformer_encoder.layers.6.linear1.weight\", \"transformer_encoder.layers.6.linear1.bias\", \"transformer_encoder.layers.6.linear2.weight\", \"transformer_encoder.layers.6.linear2.bias\", \"transformer_encoder.layers.6.norm1.weight\", \"transformer_encoder.layers.6.norm1.bias\", \"transformer_encoder.layers.6.norm2.weight\", \"transformer_encoder.layers.6.norm2.bias\", \"transformer_encoder.layers.7.self_attn.in_proj_weight\", \"transformer_encoder.layers.7.self_attn.in_proj_bias\", \"transformer_encoder.layers.7.self_attn.out_proj.weight\", \"transformer_encoder.layers.7.self_attn.out_proj.bias\", \"transformer_encoder.layers.7.linear1.weight\", \"transformer_encoder.layers.7.linear1.bias\", \"transformer_encoder.layers.7.linear2.weight\", \"transformer_encoder.layers.7.linear2.bias\", \"transformer_encoder.layers.7.norm1.weight\", \"transformer_encoder.layers.7.norm1.bias\", \"transformer_encoder.layers.7.norm2.weight\", \"transformer_encoder.layers.7.norm2.bias\", \"src_output_linear.weight\", \"src_output_linear.bias\", \"src_output_linear2.weight\", \"src_output_linear2.bias\". "
     ]
    }
   ],
   "source": [
    "model.transformer_encoder.load_state_dict(resume_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fitting: [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4397 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "total_train_loss_list = list()\n",
    "total_test_loss_list = list()\n",
    "freq = 0\n",
    "for e in range(args.num_epoch):\n",
    "    start_time_e = time.time()\n",
    "    print(f'Model Fitting: [{e+1}/{args.num_epoch}]')\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        if phase == 'valid':\n",
    "            model.eval()\n",
    "            val_f1 = 0\n",
    "            val_loss = 0\n",
    "        for src, trg, king_id in tqdm(dataloader_dict[phase]):\n",
    "            # Sourcen, Target sentence setting\n",
    "            label_sequences = trg.to(device, non_blocking=True)\n",
    "            input_sequences = src.to(device, non_blocking=True)\n",
    "            king_id = king_id.to(device, non_blocking=True)\n",
    "\n",
    "            non_pad = label_sequences != args.pad_idx\n",
    "            trg_sequences_target = label_sequences[non_pad].contiguous().view(-1)\n",
    "\n",
    "            # Target Masking\n",
    "            tgt_mask = model.generate_square_subsequent_mask(label_sequences.size(1))\n",
    "            tgt_mask = tgt_mask.to(device, non_blocking=True)\n",
    "            tgt_mask = tgt_mask.transpose(0, 1)\n",
    "\n",
    "            # Optimizer setting\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Model / Calculate loss\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                predicted = model(input_sequences, label_sequences, king_id, tgt_mask, non_pad)\n",
    "                loss = criterion(predicted, trg_sequences_target)\n",
    "                if phase == 'valid':\n",
    "                    val_loss += loss.item()\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc, top5_acc, top10_acc = accuracy(predicted, trg_sequences_target, topk=(1,5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0971, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_key_padding_mask = (input_sequences == model.pad_idx)\n",
    "trg_key_padding_mask = (label_sequences == model.pad_idx)\n",
    "\n",
    "tgt_mask = model.generate_square_subsequent_mask(label_sequences.size(1))\n",
    "tgt_mask = tgt_mask.to(device, non_blocking=True)\n",
    "tgt_mask = tgt_mask.transpose(0, 1)\n",
    "\n",
    "non_pad_position = non_pad\n",
    "trg_sequences_target = label_sequences[non_pad].contiguous().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = model.src_embedding(input_sequences, king_id).transpose(0, 1)\n",
    "decoder_out = model.trg_embedding(label_sequences).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = model.transformer_encoder(encoder_out, src_key_padding_mask=src_key_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model.decoders)):            \n",
    "    decoder_out = model.decoders[i](decoder_out, encoder_out, tgt_mask=tgt_mask,\n",
    "                        memory_key_padding_mask=src_key_padding_mask,\n",
    "                        tgt_key_padding_mask=trg_key_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_out = decoder_out.transpose(0, 1).contiguous()\n",
    "if non_pad_position is not None:\n",
    "    decoder_out = decoder_out[non_pad_position]\n",
    "\n",
    "decoder_out = model.dropout(F.gelu(model.trg_output_linear(decoder_out)))\n",
    "decoder_out = model.trg_output_linear2(decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = decoder_out.view(-1, decoder_out.size(-1))\n",
    "loss = criterion(predicted, trg_sequences_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function, absolute_import\n",
    "\n",
    "# __all__ = ['accuracy']\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
