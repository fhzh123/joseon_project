{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as torch_utils\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import Custom Module\n",
    "from translation.dataset import HanjaKoreanDataset, PadCollate, CustomDataset\n",
    "from translation.model import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='NER argparser')\n",
    "parser.add_argument('--save_path', default='./save', \n",
    "                    type=str, help='path of data pickle file (train)')\n",
    "parser.add_argument('--pad_idx', default=0, type=int, help='pad index')\n",
    "parser.add_argument('--bos_idx', default=1, type=int, help='index of bos token')\n",
    "parser.add_argument('--eos_idx', default=2, type=int, help='index of eos token')\n",
    "parser.add_argument('--unk_idx', default=3, type=int, help='index of unk token')\n",
    "\n",
    "parser.add_argument('--min_len', type=int, default=4, help='Minimum Length of Sentences; Default is 4')\n",
    "parser.add_argument('--max_len', type=int, default=150, help='Max Length of Source Sentence; Default is 150')\n",
    "parser.add_argument('--src_max_len', default=350, type=int, help='max length of the source sentence')\n",
    "parser.add_argument('--trg_max_len', default=300, type=int, help='max length of the target sentence')\n",
    "\n",
    "parser.add_argument('--num_epoch', type=int, default=10, help='Epoch count; Default is 10')\n",
    "parser.add_argument('--batch_size', type=int, default=48, help='Batch size; Default is 48')\n",
    "parser.add_argument('--crf_loss', action='store_true')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate; Default is 5e-4')\n",
    "parser.add_argument('--lr_decay', type=float, default=0.5, help='Learning rate decay; Default is 0.5')\n",
    "parser.add_argument('--lr_decay_step', type=int, default=2, help='Learning rate decay step; Default is 5')\n",
    "parser.add_argument('--grad_clip', type=int, default=5, help='Set gradient clipping; Default is 5')\n",
    "parser.add_argument('--w_decay', type=float, default=1e-6, help='Weight decay; Default is 1e-6')\n",
    "\n",
    "parser.add_argument('--d_model', type=int, default=512, help='Hidden State Vector Dimension; Default is 512')\n",
    "parser.add_argument('--d_embedding', type=int, default=256, help='Embedding Vector Dimension; Default is 256')\n",
    "parser.add_argument('--n_head', type=int, default=8, help='Multihead Count; Default is 256')\n",
    "parser.add_argument('--dim_feedforward', type=int, default=512, help='Embedding Vector Dimension; Default is 512')\n",
    "parser.add_argument('--num_encoder_layer', default=8, type=int, help='number of encoder layer')\n",
    "parser.add_argument('--num_decoder_layer', default=8, type=int, help='number of decoder layer')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='Dropout Ratio; Default is 0.5')\n",
    "\n",
    "parser.add_argument('--print_freq', type=int, default=300, help='Print train loss frequency; Default is 100')\n",
    "args = parser.parse_args(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Load & Setting!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#===================================#\n",
    "#============Data Load==============#\n",
    "#===================================#\n",
    "\n",
    "print('Data Load & Setting!')\n",
    "with open(os.path.join(args.save_path, 'nmt_processed.pkl'), 'rb') as f:\n",
    "    data_ = pickle.load(f)\n",
    "    hj_train_indices = data_['hj_train_indices']\n",
    "    hj_test_indices = data_['hj_test_indices']\n",
    "    kr_train_indices = data_['kr_train_indices']\n",
    "    kr_test_indices = data_['kr_test_indices']\n",
    "    king_train_indices = data_['king_train_indices']\n",
    "    king_test_indices = data_['king_test_indices']\n",
    "    hj_word2id = data_['hj_word2id']\n",
    "    hj_id2word = data_['hj_id2word']\n",
    "    kr_word2id = data_['kr_word2id']\n",
    "    kr_id2word = data_['kr_id2word']\n",
    "    src_vocab_num = len(hj_word2id.keys())\n",
    "    trg_vocab_num = len(kr_word2id.keys())\n",
    "    del data_\n",
    "\n",
    "#===================================#\n",
    "#========DataLoader Setting=========#\n",
    "#===================================#\n",
    "\n",
    "dataset_dict = {\n",
    "    'train': CustomDataset(hj_train_indices, kr_train_indices, king_train_indices,\n",
    "                        min_len=args.min_len, max_len=args.max_len),\n",
    "    'valid': CustomDataset(hj_test_indices, kr_test_indices, king_test_indices,\n",
    "                        min_len=args.min_len, max_len=args.max_len)\n",
    "}\n",
    "dataloader_dict = {\n",
    "    'train': DataLoader(dataset_dict['train'], collate_fn=PadCollate(), drop_last=True,\n",
    "                        batch_size=args.batch_size, shuffle=True, pin_memory=True),\n",
    "    'valid': DataLoader(dataset_dict['valid'], collate_fn=PadCollate(), drop_last=True,\n",
    "                        batch_size=args.batch_size, shuffle=True, pin_memory=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model\n",
      "Total Parameters: 69195008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (src_embedding): TransformerEmbedding_bilinear(\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_layer): Bilinear(in1_features=256, in2_features=256, out_features=512, bias=True)\n",
       "    (king_embedding): Embedding(27, 256)\n",
       "  )\n",
       "  (trg_embedding): TransformerEmbedding(\n",
       "    (token): TokenEmbedding(32000, 256, padding_idx=0)\n",
       "    (linear_layer): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (position): PositionalEmbedding()\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (trg_output_linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (trg_output_linear2): Linear(in_features=256, out_features=32000, bias=True)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (6): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (7): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0): TransformerDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (multihead_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (1): TransformerDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (multihead_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (2): TransformerDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (multihead_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (3): TransformerDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (multihead_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (4): TransformerDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (multihead_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (5): TransformerDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (multihead_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (6): TransformerDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (multihead_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (7): TransformerDecoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (multihead_attn): MultiheadAttention(\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#====================================#\n",
    "#==========DWE Results Open==========#\n",
    "#====================================#\n",
    "\n",
    "with open(os.path.join(args.save_path, 'emb_mat.pkl'), 'rb') as f:\n",
    "    emb_mat = pickle.load(f)\n",
    "\n",
    "#===================================#\n",
    "#===========Model Setting===========#\n",
    "#===================================#\n",
    "\n",
    "print(\"Build model\")\n",
    "model = Transformer(emb_mat, kr_word2id, src_vocab_num, trg_vocab_num, pad_idx=args.pad_idx, bos_idx=args.bos_idx, \n",
    "            eos_idx=args.eos_idx, max_len=args.max_len,\n",
    "            d_model=args.d_model, d_embedding=args.d_embedding, n_head=args.n_head, \n",
    "            dim_feedforward=args.dim_feedforward, dropout=args.dropout,\n",
    "            num_encoder_layer=args.num_encoder_layer, num_decoder_layer=args.num_decoder_layer,\n",
    "            device=device)\n",
    "print(\"Total Parameters:\", sum([p.nelement() for p in model.parameters()]))\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr, weight_decay=args.w_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_decay_step, gamma=args.lr_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fitting: [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4397 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "total_train_loss_list = list()\n",
    "total_test_loss_list = list()\n",
    "freq = 0\n",
    "for e in range(args.num_epoch):\n",
    "    start_time_e = time.time()\n",
    "    print(f'Model Fitting: [{e+1}/{args.num_epoch}]')\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        if phase == 'valid':\n",
    "            model.eval()\n",
    "            val_f1 = 0\n",
    "            val_loss = 0\n",
    "        for src, trg, king_id in tqdm(dataloader_dict[phase]):\n",
    "            # Sourcen, Target sentence setting\n",
    "            label_sequences = trg.to(device, non_blocking=True)\n",
    "            input_sequences = src.to(device, non_blocking=True)\n",
    "            king_id = king_id.to(device, non_blocking=True)\n",
    "\n",
    "            non_pad = label_sequences != args.pad_idx\n",
    "            trg_sequences_target = label_sequences[non_pad].contiguous().view(-1)\n",
    "\n",
    "            # Target Masking\n",
    "            tgt_mask = model.generate_square_subsequent_mask(label_sequences.size(1))\n",
    "            tgt_mask = tgt_mask.to(device, non_blocking=True)\n",
    "            tgt_mask = tgt_mask.transpose(0, 1)\n",
    "\n",
    "            # Optimizer setting\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Model / Calculate loss\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                predicted = model(input_sequences, label_sequences, king_id, tgt_mask, non_pad)\n",
    "                loss = criterion(predicted, trg_sequences_target)\n",
    "                if phase == 'valid':\n",
    "                    val_loss += loss.item()\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc, top5_acc, top10_acc = accuracy(predicted, trg_sequences_target, topk=(1,5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0971, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_key_padding_mask = (input_sequences == model.pad_idx)\n",
    "trg_key_padding_mask = (label_sequences == model.pad_idx)\n",
    "\n",
    "tgt_mask = model.generate_square_subsequent_mask(label_sequences.size(1))\n",
    "tgt_mask = tgt_mask.to(device, non_blocking=True)\n",
    "tgt_mask = tgt_mask.transpose(0, 1)\n",
    "\n",
    "non_pad_position = non_pad\n",
    "trg_sequences_target = label_sequences[non_pad].contiguous().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = model.src_embedding(input_sequences, king_id).transpose(0, 1)\n",
    "decoder_out = model.trg_embedding(label_sequences).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = model.transformer_encoder(encoder_out, src_key_padding_mask=src_key_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model.decoders)):            \n",
    "    decoder_out = model.decoders[i](decoder_out, encoder_out, tgt_mask=tgt_mask,\n",
    "                        memory_key_padding_mask=src_key_padding_mask,\n",
    "                        tgt_key_padding_mask=trg_key_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_out = decoder_out.transpose(0, 1).contiguous()\n",
    "if non_pad_position is not None:\n",
    "    decoder_out = decoder_out[non_pad_position]\n",
    "\n",
    "decoder_out = model.dropout(F.gelu(model.trg_output_linear(decoder_out)))\n",
    "decoder_out = model.trg_output_linear2(decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = decoder_out.view(-1, decoder_out.size(-1))\n",
    "loss = criterion(predicted, trg_sequences_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function, absolute_import\n",
    "\n",
    "# __all__ = ['accuracy']\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
